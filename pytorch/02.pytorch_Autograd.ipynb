{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autograd.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf4N_nqu0oFB"
      },
      "source": [
        "# Pytorch 패키지 구성\r\n",
        "\r\n",
        "- torch : 메인 네임스페이스로 텐서 등의 다양한 수학 함수가 포함. numpy와 같은 구조를 가지고 있다\r\n",
        "\r\n",
        "- torch.autograd : 자동 미분을 위한 함수가 포함. \r\n",
        "자동 미분의 on/off를 제어하는 콘텍스트 매니저(enable_grad/no_grad)나 자체 미분 가능 함수를 정의할 때 사용하는 'function'등을 포함\r\n",
        "\r\n",
        "- toch.nn : 신경망을 구축하기 위한 다양한 데이터 구조나 레이어 등이 정의. Convolution이나 LTSM, ReLU 등의 활성화 함수나 MSELoss등의 손실함수를 포함\r\n",
        "\r\n",
        "- torch.optim : 확률적 경사 하강법(SGD, Stochastic Gradient Descent)을 중심으로 한 파라미터 최적화 알고리즘이 구현되어 있다\r\n",
        "\r\n",
        "- torch.utils.data : SGD의 반복 연산을 실행할 때 사용하는 미니 배치용 유틸리티 함수가 포함\r\n",
        "\r\n",
        "- torch.onnx : ONNX(Open Neural Network Exchange) 포맷으로 모델을 export할 때 사용. ONNX는 서로 다른 딥러닝 프레임워크 간에 모델을 공유할 때 사용하는 새로운 포맷\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFU4ZtzYGcco"
      },
      "source": [
        "# Tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yECN-lKaEsIp"
      },
      "source": [
        "- .requires_grad 속성을 True로 설정하면, 그 tensor에서 이뤄진 모든 연산들을 추적(track)하기 시작\r\n",
        "- 계산이 완료된 후, .backward()를 호출하면 모든 변화도(gradient)를 자동으로 계산할 수 있다\r\n",
        "- tensor의 변화도는 .grad 속성에 누적된다\r\n",
        "\r\n",
        "- tensor가 기록되는 것을 중단할려면 .detach를 호출하여 연산 기록으로부터 분리하여 이후 연산들이 추적되는 것을 방지할 수 있다\r\n",
        "- tensor와 Function은 서로 연결되어 있다\r\n",
        "- tensor은 .grad_fn 속성을 가지고 있는데, 이는 tensor을 생성한 function을 참조하고 있다.( 단, 사용자가 만든 tensor은 예외로, 이 때의 .grad_fn은 None을 가진다)\r\n",
        "- 도함수를 계산하기 위해서는 tensor의 .backward()를 호출하면 된다. 만약 tensor가 스칼라인 경우에는 backward의 인자를 정해줄 필요가 없다. 하지만 여러 개의 요소를 가지고 있을 때는 tensor의 모양을 gradient의 인자로 지정해야함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdCmSmPH2Bqa"
      },
      "source": [
        "## 자동 미분 계산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzCxjpxcG13j"
      },
      "source": [
        ".requires_grad_( ... )는 기존 Tensor의 requires_grad 값을 in-place하여 변경. \r\n",
        "입력값이 지정되지 않으면 기본값은 False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfslVA4o2HNc",
        "outputId": "945bc1d0-1d2e-4219-a089-70539fac4759"
      },
      "source": [
        "import torch\r\n",
        "\r\n",
        "# 텐서 생성 / 변수 선언(+데이터 입력)\r\n",
        "# requires_grad=True 를 설정하여 연산을 기록 \r\n",
        "# x에 대해서 미분할 수 있도록 x에 관한 연산들을 모두 추적할 수 있게 한다.\r\n",
        "x = torch.ones(2,2,requires_grad = True)\r\n",
        "print(x)\r\n",
        "\r\n",
        "# 텐서 연산 / 모델 내 연산 예측값 산출\r\n",
        "y = x+2\r\n",
        "print(y)\r\n",
        "print('\\n')\r\n",
        "\r\n",
        "# y는 연산의 결과로 생성된 것이기 떄문에 grad_fn을 가지게 된다\r\n",
        "print(y.grad_fn)\r\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n",
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n",
            "\n",
            "\n",
            "<AddBackward0 object at 0x7fc21437b668>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vx7ex-vCvXY4",
        "outputId": "8e5e7b92-a58c-445e-a375-21dc88df12a5"
      },
      "source": [
        "a = torch.randn(2, 2)\r\n",
        "a = ((a * 3) / (a - 1))\r\n",
        "print(a.requires_grad)\r\n",
        "a.requires_grad_(True)\r\n",
        "print(a.requires_grad)\r\n",
        "b = (a * a).sum()\r\n",
        "print(b.grad_fn)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n",
            "<SumBackward0 object at 0x7fc1c7c82780>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4g_iRRWT2S3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2416e666-eb2c-4f4f-e1ef-6e2a0e15f0d6"
      },
      "source": [
        "# tensor 연산\r\n",
        "z = 3*y**2\r\n",
        "# 평균\r\n",
        "# 전체평균\r\n",
        "out = z.mean() # z,mean(dim=0) : 첫 번째 차원단위 평균 / z.mean(dim=1) : 두 번째 차원단위 평균\r\n",
        "\r\n",
        "print(z)\r\n",
        "print(out)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>)\n",
            "tensor(27., grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhtk6XHLwyS4"
      },
      "source": [
        "# 변화도(Gradient)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL5qOBouw2ZA"
      },
      "source": [
        "out 은 하나의 스칼라 값만 갖고 있기 때문에, out.backward() 는 out.backward(torch.tensor(1.)) 과 동일\r\n",
        "\r\n",
        "- 자코비안 행렬 : 벡터를 벡터로 미분하면 생기는 행렬"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8pOobdIwii2",
        "outputId": "5255a5b4-a0f0-4da6-a21d-56497f0502f3"
      },
      "source": [
        "# out 값을 미분하여 최적화\r\n",
        "out.backward()\r\n",
        "# x에 대한 미분값 확인\r\n",
        "print(x.grad)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCvm-rJDwwt_",
        "outputId": "65a14250-aaee-4dad-bb4b-31a5743d4743"
      },
      "source": [
        "x = torch.randn(3, requires_grad=True)\r\n",
        "\r\n",
        "y = x * 2\r\n",
        "while y.data.norm() < 1000:\r\n",
        "    y = y * 2\r\n",
        "\r\n",
        "print(y)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-364.2000, 1450.9998,  522.7003], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWNco3ER39fP",
        "outputId": "7bdab61d-5fda-49cb-c554-c688d0bc5e5e"
      },
      "source": [
        "gradients = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\r\n",
        "y.backward(gradients)\r\n",
        "\r\n",
        "print(x.grad)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qw93979887FW"
      },
      "source": [
        "with torch.no_grad(): 로 코드블럭을 감싸면 autograd가 .requires_gred=True 인 tensor들의 연산 기록 추적을 멈출 수 있다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsoWl_uk8Ce_",
        "outputId": "e1ffdff3-0aef-47e7-d08d-4aaa1c54e5f6"
      },
      "source": [
        "print(x.requires_grad)\r\n",
        "print((x ** 2).requires_grad)\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "    print((x ** 2).requires_grad)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceqjLfGf86Qt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}